{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'best_decision_tree_model.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 30\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Cargar los modelos previamente entrenados:\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# (Usa los modelos entrenados de los archivos \"01 - modelo 1.ipynb\" y \"02 - modelo 2.ipynb\")\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Suponiendo que ya tenemos los mejores modelos de ambos archivos\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Si no están cargados en memoria, puedes volver a cargarlos (dependiendo de cómo guardaste los modelos).\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Cargar el modelo de Árbol de Decisión (mejor modelo de 01 - modelo 1.ipynb)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load\n\u001b[1;32m---> 30\u001b[0m dt_model \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_decision_tree_model.joblib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Cargar el modelo de Random Forest (mejor modelo de 02 - modelo 2.ipynb)\u001b[39;00m\n\u001b[0;32m     33\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_random_forest_model.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\BrayhanFelipeSanchez\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best_decision_tree_model.joblib'"
     ]
    }
   ],
   "source": [
    "# 03 - comparación.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cargar los datos\n",
    "df = pd.read_csv('dataset.csv', delimiter=';', encoding='utf-8')\n",
    "\n",
    "# Asegurarse de que los nombres de las columnas no tengan espacios\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Separar las variables independientes (X) y la variable dependiente (y)\n",
    "X = df.drop('Target', axis=1)  # Variables independientes\n",
    "y = df['Target']  # Variable dependiente\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Cargar los modelos previamente entrenados:\n",
    "# (Usa los modelos entrenados de los archivos \"01 - modelo 1.ipynb\" y \"02 - modelo 2.ipynb\")\n",
    "# Suponiendo que ya tenemos los mejores modelos de ambos archivos\n",
    "# Si no están cargados en memoria, puedes volver a cargarlos (dependiendo de cómo guardaste los modelos).\n",
    "\n",
    "# Cargar el modelo de Árbol de Decisión (mejor modelo de 01 - modelo 1.ipynb)\n",
    "from joblib import load\n",
    "dt_model = load('best_decision_tree_model.joblib')\n",
    "\n",
    "# Cargar el modelo de Random Forest (mejor modelo de 02 - modelo 2.ipynb)\n",
    "rf_model = load('best_random_forest_model.joblib')\n",
    "\n",
    "# Predicción con ambos modelos\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluación de desempeño de ambos modelos\n",
    "print(\"Métricas de clasificación - Árbol de Decisión:\\n\", classification_report(y_test, y_pred_dt))\n",
    "print(\"Métricas de clasificación - Random Forest:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Comparar las matrices de confusión\n",
    "conf_matrix_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "# Matriz de confusión de Árbol de Decisión\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix_dt, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=df['Target'].unique(), yticklabels=df['Target'].unique())\n",
    "plt.title(\"Matriz de Confusión - Árbol de Decisión\")\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.show()\n",
    "\n",
    "# Matriz de confusión de Random Forest\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix_rf, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=df['Target'].unique(), yticklabels=df['Target'].unique())\n",
    "plt.title(\"Matriz de Confusión - Random Forest\")\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.show()\n",
    "\n",
    "# Análisis de la concordancia entre ambos modelos utilizando Cohen's Kappa\n",
    "kappa = cohen_kappa_score(y_pred_dt, y_pred_rf)\n",
    "print(f'Índice de concordancia (Cohen\\'s Kappa) entre Árbol de Decisión y Random Forest: {kappa}')\n",
    "\n",
    "# Comentario sobre el Kappa:\n",
    "# Si el valor de kappa es cercano a 1, significa que ambos modelos están de acuerdo en las predicciones.\n",
    "# Un valor cercano a 0 sugiere que las predicciones de los modelos son independientes.\n",
    "# Un valor negativo indica que los modelos están en desacuerdo.\n",
    "\n",
    "# Comparación visual de las curvas de aprendizaje\n",
    "# Cargar las curvas de aprendizaje de ambos modelos (si las has guardado previamente)\n",
    "# O generar las curvas desde el principio (como se mostró en los modelos individuales)\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Curvas de aprendizaje para el Árbol de Decisión\n",
    "train_sizes_dt, train_scores_dt, test_scores_dt = learning_curve(dt_model, X, y, cv=5, train_sizes=np.linspace(0.1, 1.0, 5))\n",
    "# Curvas de aprendizaje para el Random Forest\n",
    "train_sizes_rf, train_scores_rf, test_scores_rf = learning_curve(rf_model, X, y, cv=5, train_sizes=np.linspace(0.1, 1.0, 5))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Curvas de aprendizaje - Árbol de Decisión\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_sizes_dt, np.mean(train_scores_dt, axis=1), label=\"Entrenamiento\")\n",
    "plt.plot(train_sizes_dt, np.mean(test_scores_dt, axis=1), label=\"Prueba\")\n",
    "plt.title(\"Curvas de Aprendizaje - Árbol de Decisión\")\n",
    "plt.xlabel(\"Tamaño del conjunto de entrenamiento\")\n",
    "plt.ylabel(\"Puntuación\")\n",
    "plt.legend()\n",
    "\n",
    "# Curvas de aprendizaje - Random Forest\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_sizes_rf, np.mean(train_scores_rf, axis=1), label=\"Entrenamiento\")\n",
    "plt.plot(train_sizes_rf, np.mean(test_scores_rf, axis=1), label=\"Prueba\")\n",
    "plt.title(\"Curvas de Aprendizaje - Random Forest\")\n",
    "plt.xlabel(\"Tamaño del conjunto de entrenamiento\")\n",
    "plt.ylabel(\"Puntuación\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
